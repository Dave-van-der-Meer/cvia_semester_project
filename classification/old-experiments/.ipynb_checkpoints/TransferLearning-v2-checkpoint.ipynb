{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kymKPWIS9QHA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 72000 images belonging to 11 classes.\n",
      "Found 18000 images belonging to 11 classes.\n"
     ]
    }
   ],
   "source": [
    "# create a data generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    brightness_range=[1.0, 1.75],\n",
    "    zoom_range=[1.0, 1.5],\n",
    "    horizontal_flip = True,\n",
    "    validation_split=0.2)\n",
    "\n",
    "# load and iterate training dataset\n",
    "train_it = datagen.flow_from_directory(\n",
    "    '../master-data/train_large/rgb', \n",
    "    target_size=(224, 224),\n",
    "    subset=\"training\", \n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    batch_size=512)\n",
    "\n",
    "val_it = datagen.flow_from_directory(\n",
    "    '../master-data/train_large/rgb', \n",
    "    target_size=(224, 224), \n",
    "    subset=\"validation\", \n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 17:28:24.319168: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2021-11-24 17:28:24.818857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:1a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-11-24 17:28:24.821190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: \n",
      "pciBusID: 0000:1c:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-11-24 17:28:24.823433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties: \n",
      "pciBusID: 0000:1d:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-11-24 17:28:24.825588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties: \n",
      "pciBusID: 0000:1e:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-11-24 17:28:24.842135: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-24 17:28:24.930930: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-24 17:28:24.982968: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-24 17:28:25.059918: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-24 17:28:25.108552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-24 17:28:25.160070: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-24 17:28:25.216149: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-24 17:28:25.238840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2021-11-24 17:28:25.240203: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2021-11-24 17:28:25.254161: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2600000000 Hz\n",
      "2021-11-24 17:28:25.254840: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4bb41e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-24 17:28:25.254872: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2021-11-24 17:28:25.768973: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x43b5440 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2021-11-24 17:28:25.769032: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2021-11-24 17:28:25.769081: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2021-11-24 17:28:25.769099: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (2): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2021-11-24 17:28:25.769116: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (3): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2021-11-24 17:28:25.777336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: \n",
      "pciBusID: 0000:1a:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-11-24 17:28:25.780393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 1 with properties: \n",
      "pciBusID: 0000:1c:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-11-24 17:28:25.783576: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 2 with properties: \n",
      "pciBusID: 0000:1d:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-11-24 17:28:25.786404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 3 with properties: \n",
      "pciBusID: 0000:1e:00.0 name: Tesla V100-SXM2-32GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2021-11-24 17:28:25.786473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-24 17:28:25.786504: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-24 17:28:25.786532: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2021-11-24 17:28:25.786559: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2021-11-24 17:28:25.786585: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2021-11-24 17:28:25.786611: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2021-11-24 17:28:25.786637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2021-11-24 17:28:25.807156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0, 1, 2, 3\n",
      "2021-11-24 17:28:25.807230: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2021-11-24 17:28:25.817356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-11-24 17:28:25.817382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 1 2 3 \n",
      "2021-11-24 17:28:25.817400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N Y Y Y \n",
      "2021-11-24 17:28:25.817412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 1:   Y N Y Y \n",
      "2021-11-24 17:28:25.817424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 2:   Y Y N Y \n",
      "2021-11-24 17:28:25.817435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 3:   Y Y Y N \n",
      "2021-11-24 17:28:25.828724: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 30269 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1a:00.0, compute capability: 7.0)\n",
      "2021-11-24 17:28:25.831533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 30269 MB memory) -> physical GPU (device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1c:00.0, compute capability: 7.0)\n",
      "2021-11-24 17:28:25.834305: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 30269 MB memory) -> physical GPU (device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1d:00.0, compute capability: 7.0)\n",
      "2021-11-24 17:28:25.837056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 30269 MB memory) -> physical GPU (device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1e:00.0, compute capability: 7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of devices: 4\n",
      "Epoch 1/16\n",
      "INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-24 17:29:07.433090: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2021-11-24 17:29:46.338537: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - ETA: 0s - loss: 2.1118 - acc: 0.2991INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "\n",
      "Epoch 00001: val_loss improved from -inf to 1.88298, saving model to best_model.h5\n",
      "141/141 [==============================] - 646s 5s/step - loss: 2.1118 - acc: 0.2991 - val_loss: 1.8830 - val_acc: 0.3552\n",
      "Epoch 2/16\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.4684 - acc: 0.4836\n",
      "Epoch 00002: val_loss did not improve from 1.88298\n",
      "141/141 [==============================] - 652s 5s/step - loss: 1.4684 - acc: 0.4836 - val_loss: 1.6796 - val_acc: 0.4362\n",
      "Epoch 3/16\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2988 - acc: 0.5419\n",
      "Epoch 00003: val_loss did not improve from 1.88298\n",
      "141/141 [==============================] - 652s 5s/step - loss: 1.2988 - acc: 0.5419 - val_loss: 1.6095 - val_acc: 0.4537\n",
      "Epoch 4/16\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.2212 - acc: 0.5656\n",
      "Epoch 00004: val_loss did not improve from 1.88298\n",
      "141/141 [==============================] - 643s 5s/step - loss: 1.2212 - acc: 0.5656 - val_loss: 1.5853 - val_acc: 0.4874\n",
      "Epoch 5/16\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1774 - acc: 0.5813\n",
      "Epoch 00005: val_loss did not improve from 1.88298\n",
      "141/141 [==============================] - 648s 5s/step - loss: 1.1774 - acc: 0.5813 - val_loss: 1.5152 - val_acc: 0.5212\n",
      "Epoch 6/16\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.1176 - acc: 0.6041\n",
      "Epoch 00006: val_loss did not improve from 1.88298\n",
      "141/141 [==============================] - 649s 5s/step - loss: 1.1176 - acc: 0.6041 - val_loss: 1.4642 - val_acc: 0.5334\n",
      "Epoch 7/16\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0935 - acc: 0.6095\n",
      "Epoch 00007: val_loss did not improve from 1.88298\n",
      "141/141 [==============================] - 645s 5s/step - loss: 1.0935 - acc: 0.6095 - val_loss: 1.5473 - val_acc: 0.5023\n",
      "Epoch 8/16\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0689 - acc: 0.6183\n",
      "Epoch 00008: val_loss did not improve from 1.88298\n",
      "141/141 [==============================] - 636s 5s/step - loss: 1.0689 - acc: 0.6183 - val_loss: 1.4750 - val_acc: 0.5303\n",
      "Epoch 9/16\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0487 - acc: 0.6256\n",
      "Epoch 00009: val_loss did not improve from 1.88298\n",
      "141/141 [==============================] - 624s 4s/step - loss: 1.0487 - acc: 0.6256 - val_loss: 1.5190 - val_acc: 0.5300\n",
      "Epoch 10/16\n",
      "141/141 [==============================] - ETA: 0s - loss: 1.0231 - acc: 0.6334\n",
      "Epoch 00010: val_loss did not improve from 1.88298\n",
      "141/141 [==============================] - 612s 4s/step - loss: 1.0231 - acc: 0.6334 - val_loss: 1.4101 - val_acc: 0.5372\n",
      "Epoch 11/16\n",
      " 36/141 [======>.......................] - ETA: 4:01 - loss: 0.9931 - acc: 0.6428"
     ]
    }
   ],
   "source": [
    "# Create a MirroredStrategy.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='max', verbose=1, save_best_only=True)\n",
    "\n",
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "  # Everything that creates variables should be under the strategy scope.\n",
    "  # In general this is only model construction & `compile()`.\n",
    "    conv_model = VGG16(weights='imagenet', include_top=False, classes=11, input_shape=(224,224,3))\n",
    "    for layer in conv_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # flatten the output of the convolutional part: \n",
    "    x = Flatten()(conv_model.output)\n",
    "    # three hidden layers\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "\n",
    "    # final softmax layer\n",
    "    predictions = Dense(11, activation='softmax')(x)\n",
    "\n",
    "    # creating the full model:\n",
    "    full_model = Model(inputs=conv_model.input, outputs=predictions)\n",
    "\n",
    "    full_model.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=Adam(),\n",
    "                      metrics=['acc'])\n",
    "\n",
    "# Train the model on all available devices.\n",
    "history = full_model.fit(train_it, validation_data = val_it, workers=14, epochs=16, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    '''Plot loss and accuracy as a function of the epoch,\n",
    "    for the training and validation datasets.\n",
    "    '''\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    # Get number of epochs\n",
    "    epochs = range(len(acc))\n",
    "\n",
    "    # Plot training and validation accuracy per epoch\n",
    "    plt.plot(epochs, acc, label=\"acc\")\n",
    "    plt.plot(epochs, val_acc, label=\"val_acc\")\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot training and validation loss per epoch\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(epochs, loss, label=\"loss\")\n",
    "    plt.plot(epochs, val_loss, label=\"val_loss\")\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SjF3_pGFxaf0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 10/50\n",
    "282/282 [==============================] - 601s 2s/step - acc: 0.6664 - loss: 0.9677 - val_acc: 0.5649 - val_loss: 1.4936"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TransferLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
